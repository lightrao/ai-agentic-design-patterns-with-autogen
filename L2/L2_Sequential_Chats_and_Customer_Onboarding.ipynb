{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lightrao/ai-agentic-design-patterns-with-autogen/blob/main/L2/L2_Sequential_Chats_and_Customer_Onboarding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8140b161",
      "metadata": {
        "id": "8140b161"
      },
      "source": [
        "# Lesson 2: Sequential Chats and Customer Onboarding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d4d307",
      "metadata": {
        "id": "e9d4d307"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pyautogen chess numpy matplotlib pandas yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FaUzY9FtgFvk",
        "outputId": "b43b94a5-1f7e-435c-c61b-eca38aa6c77f"
      },
      "id": "FaUzY9FtgFvk",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.8.6-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting chess\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (4.9.0)\n",
            "Collecting asyncer==0.0.8 (from pyautogen)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting diskcache (from pyautogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pyautogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from pyautogen) (2.11.3)\n",
            "Collecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen) (3.0.1)\n",
            "Collecting tiktoken (from pyautogen)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->pyautogen) (4.13.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->pyautogen) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->pyautogen) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->pyautogen) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->pyautogen) (2024.11.6)\n",
            "Downloading pyautogen-0.8.6-py3-none-any.whl (734 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.2/734.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=2440526ddcec124610ed9a240efea93244e7a4100291c2edb357890264cac1b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built chess\n",
            "Installing collected packages: python-dotenv, diskcache, chess, tiktoken, docker, asyncer, pyautogen\n",
            "Successfully installed asyncer-0.0.8 chess-1.11.2 diskcache-5.6.3 docker-7.1.0 pyautogen-0.8.6 python-dotenv-1.1.0 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "iLr5bhgHgG0L"
      },
      "id": "iLr5bhgHgG0L",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "24b75995-4ee4-4ff0-9c44-3943caae37e7",
      "metadata": {
        "height": 31,
        "id": "24b75995-4ee4-4ff0-9c44-3943caae37e7"
      },
      "outputs": [],
      "source": [
        "llm_config={\"model\": \"gpt-3.5-turbo\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "20ce6700-8a33-424f-aefe-8852fd1e6d07",
      "metadata": {
        "height": 31,
        "id": "20ce6700-8a33-424f-aefe-8852fd1e6d07"
      },
      "outputs": [],
      "source": [
        "from autogen import ConversableAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f979f9",
      "metadata": {
        "id": "76f979f9"
      },
      "source": [
        "## Creating the needed agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a527bb1e-dd4e-47b0-a1b7-a9cbcd87cbdb",
      "metadata": {
        "height": 201,
        "id": "a527bb1e-dd4e-47b0-a1b7-a9cbcd87cbdb"
      },
      "outputs": [],
      "source": [
        "onboarding_personal_information_agent = ConversableAgent(\n",
        "    name=\"Onboarding_Personal_Information_Agent\",\n",
        "    system_message='''You are a helpful customer onboarding agent,\n",
        "    you are here to help new customers get started with our product.\n",
        "    Your job is to gather customer's name and location.\n",
        "    Do not ask for other information. Return 'TERMINATE'\n",
        "    when you have gathered all the information.''',\n",
        "    llm_config=llm_config,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51bc9a24-a680-444d-943b-b740bce0189d",
      "metadata": {
        "height": 201,
        "id": "51bc9a24-a680-444d-943b-b740bce0189d"
      },
      "outputs": [],
      "source": [
        "onboarding_topic_preference_agent = ConversableAgent(\n",
        "    name=\"Onboarding_Topic_preference_Agent\",\n",
        "    system_message='''You are a helpful customer onboarding agent,\n",
        "    you are here to help new customers get started with our product.\n",
        "    Your job is to gather customer's preferences on news topics.\n",
        "    Do not ask for other information.\n",
        "    Return 'TERMINATE' when you have gathered all the information.''',\n",
        "    llm_config=llm_config,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6755a7fc-cb17-4d62-a03f-48e260f39010",
      "metadata": {
        "height": 235,
        "id": "6755a7fc-cb17-4d62-a03f-48e260f39010"
      },
      "outputs": [],
      "source": [
        "customer_engagement_agent = ConversableAgent(\n",
        "    name=\"Customer_Engagement_Agent\",\n",
        "    system_message='''You are a helpful customer service agent\n",
        "    here to provide fun for the customer based on the user's\n",
        "    personal information and topic preferences.\n",
        "    This could include fun facts, jokes, or interesting stories.\n",
        "    Make sure to make it engaging and fun!\n",
        "    Return 'TERMINATE' when you are done.''',\n",
        "    llm_config=llm_config,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64267c0b-f7f2-46e6-ab44-6f7b5fbd9db7",
      "metadata": {
        "height": 133,
        "id": "64267c0b-f7f2-46e6-ab44-6f7b5fbd9db7"
      },
      "outputs": [],
      "source": [
        "customer_proxy_agent = ConversableAgent(\n",
        "    name=\"customer_proxy_agent\",\n",
        "    llm_config=False,\n",
        "    code_execution_config=False,\n",
        "    human_input_mode=\"ALWAYS\",\n",
        "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f240408",
      "metadata": {
        "id": "4f240408"
      },
      "source": [
        "## Creating tasks\n",
        "\n",
        "Now, you can craft a series of tasks to facilitate the onboarding process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b15af1d-7042-4569-a936-7966be203f05",
      "metadata": {
        "height": 592,
        "id": "2b15af1d-7042-4569-a936-7966be203f05"
      },
      "outputs": [],
      "source": [
        "chats = [\n",
        "    {\n",
        "        \"sender\": onboarding_personal_information_agent,\n",
        "        \"recipient\": customer_proxy_agent,\n",
        "        \"message\":\n",
        "            \"Hello, I'm here to help you get started with our product.\"\n",
        "            \"Could you tell me your name and location?\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_args\": {\n",
        "            \"summary_prompt\" : \"Return the customer information \"\n",
        "                             \"into as JSON object only: \"\n",
        "                             \"{'name': '', 'location': ''}\",\n",
        "        },\n",
        "        \"max_turns\": 2,\n",
        "        \"clear_history\" : True\n",
        "    },\n",
        "    {\n",
        "        \"sender\": onboarding_topic_preference_agent,\n",
        "        \"recipient\": customer_proxy_agent,\n",
        "        \"message\":\n",
        "                \"Great! Could you tell me what topics you are \"\n",
        "                \"interested in reading about?\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"max_turns\": 1,\n",
        "        \"clear_history\" : False\n",
        "    },\n",
        "    {\n",
        "        \"sender\": customer_proxy_agent,\n",
        "        \"recipient\": customer_engagement_agent,\n",
        "        \"message\": \"Let's find something fun to read.\",\n",
        "        \"max_turns\": 1,\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862a066b",
      "metadata": {
        "id": "862a066b"
      },
      "source": [
        "## Start the onboarding process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0fa8f99",
      "metadata": {
        "id": "e0fa8f99"
      },
      "source": [
        "**Note**: You might get a slightly different response than what's shown in the video. Feel free to try different inputs, such as name, location, and preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9d6d1d4a-0b50-41a5-a1f0-3ff208398bc6",
      "metadata": {
        "height": 65,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6d1d4a-0b50-41a5-a1f0-3ff208398bc6",
        "outputId": "24f76852-0d14-4dbd-a799-7e01b112a3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Onboarding_Personal_Information_Agent (to customer_proxy_agent):\n",
            "\n",
            "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/autogen/agentchat/chat.py:57: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replying as customer_proxy_agent. Provide feedback to Onboarding_Personal_Information_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: lightrao\n",
            "customer_proxy_agent (to Onboarding_Personal_Information_Agent):\n",
            "\n",
            "lightrao\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Onboarding_Personal_Information_Agent (to customer_proxy_agent):\n",
            "\n",
            "I'm sorry, could you please provide me with your name and location to proceed further?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as customer_proxy_agent. Provide feedback to Onboarding_Personal_Information_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: New York\n",
            "customer_proxy_agent (to Onboarding_Personal_Information_Agent):\n",
            "\n",
            "New York\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (ebce92f9-0fca-4044-9531-9ff046670fff): Maximum turns (2) reached\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Onboarding_Topic_preference_Agent (to customer_proxy_agent):\n",
            "\n",
            "Great! Could you tell me what topics you are interested in reading about?\n",
            "Context: \n",
            "{'name': 'lightrao', 'location': 'New York'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Replying as customer_proxy_agent. Provide feedback to Onboarding_Topic_preference_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: AI\n",
            "customer_proxy_agent (to Onboarding_Topic_preference_Agent):\n",
            "\n",
            "AI\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (a89611fd-5a9f-4aba-9ac5-bec931e94539): Maximum turns (1) reached\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "customer_proxy_agent (to Customer_Engagement_Agent):\n",
            "\n",
            "Let's find something fun to read.\n",
            "Context: \n",
            "{'name': 'lightrao', 'location': 'New York'}\n",
            "The customer is interested in reading about AI.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Customer_Engagement_Agent (to customer_proxy_agent):\n",
            "\n",
            "Hello lightrao from New York! Did you know that in the world of AI, there is a concept called \"Deep Learning,\" which is a subset of machine learning where artificial neural networks modelled after the human brain learn from large amounts of data? It's fascinating how technology can mimic the functioning of our brains to solve complex problems! If you're interested in diving deeper into AI, you might enjoy exploring how neural networks work and their applications in various fields. Happy reading!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (217ad602-eb1d-4ea0-bebf-d0629a8718c6): Maximum turns (1) reached\n"
          ]
        }
      ],
      "source": [
        "from autogen import initiate_chats\n",
        "\n",
        "chat_results = initiate_chats(chats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f9e2713",
      "metadata": {
        "id": "4f9e2713"
      },
      "source": [
        "## Print out the summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1e122f8a-1ceb-4635-9672-662114b0552a",
      "metadata": {
        "height": 65,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e122f8a-1ceb-4635-9672-662114b0552a",
        "outputId": "3e4892d4-7089-4206-d65a-021be7de2fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'lightrao', 'location': 'New York'}\n",
            "\n",
            "\n",
            "The customer is interested in reading about AI.\n",
            "\n",
            "\n",
            "lightrao from New York is interested in reading about AI and may enjoy exploring the concept of Deep Learning, which involves artificial neural networks modelled after the human brain to solve complex problems.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for chat_result in chat_results:\n",
        "    print(chat_result.summary)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a674c4eb",
      "metadata": {
        "id": "a674c4eb"
      },
      "source": [
        "## Print out the cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8b82a10a-afe5-4ba3-97b4-41c8c14b739f",
      "metadata": {
        "height": 65,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b82a10a-afe5-4ba3-97b4-41c8c14b739f",
        "outputId": "7c44656f-afb4-4b40-fb38-a42f01849a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'usage_including_cached_inference': {'total_cost': 0.00017, 'gpt-3.5-turbo-0125': {'cost': 0.00017, 'prompt_tokens': 232, 'completion_tokens': 36, 'total_tokens': 268}}, 'usage_excluding_cached_inference': {'total_cost': 0.00017, 'gpt-3.5-turbo-0125': {'cost': 0.00017, 'prompt_tokens': 232, 'completion_tokens': 36, 'total_tokens': 268}}}\n",
            "\n",
            "\n",
            "{'usage_including_cached_inference': {'total_cost': 5.4e-05, 'gpt-3.5-turbo-0125': {'cost': 5.4e-05, 'prompt_tokens': 78, 'completion_tokens': 10, 'total_tokens': 88}}, 'usage_excluding_cached_inference': {'total_cost': 5.4e-05, 'gpt-3.5-turbo-0125': {'cost': 5.4e-05, 'prompt_tokens': 78, 'completion_tokens': 10, 'total_tokens': 88}}}\n",
            "\n",
            "\n",
            "{'usage_including_cached_inference': {'total_cost': 0.000352, 'gpt-3.5-turbo-0125': {'cost': 0.000352, 'prompt_tokens': 290, 'completion_tokens': 138, 'total_tokens': 428}}, 'usage_excluding_cached_inference': {'total_cost': 0.000352, 'gpt-3.5-turbo-0125': {'cost': 0.000352, 'prompt_tokens': 290, 'completion_tokens': 138, 'total_tokens': 428}}}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for chat_result in chat_results:\n",
        "    print(chat_result.cost)\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}